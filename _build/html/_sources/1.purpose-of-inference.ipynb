{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a6b3fd6-1753-45e7-a920-fccf68cbdcac",
   "metadata": {},
   "source": [
    "# The Purpose of Statistical Inference\n",
    "In our previous weeks, we have established a very general framework for statistical modelling and have examined one particular case in the form of simple/multiple regression. Throughout all of this, our aim was to say something about a *population* on the basis of a *sample*. At the end of the previous lesson, we were left with an estimated model that we visualised and interpreted in a very general sense. However, it is important to remind ourseleves that we are not really interested in the *estimates* per-se. What we are interested in is the *population values*. We may well have a slope estimate of $\\hat{\\beta}_{1} = -3.80$, but our real question is whether the *real* slope is equal to $-3.80$, or whether $-3.80$ is even close to the real value? In general saying something about only a single specific group of measurements is not very useful scientifically. However, saying something much more general *is* very useful because we can make predictions about the future, allowing us to implement changes that have real-world consequences and develop theories that apply to the population as a whole. Our desire is therefore to go from results in one specific sample and generalise much more widely. This seems a noble aim. However, there are some deep philosophical issues with attempting to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61418881",
   "metadata": {},
   "source": [
    "## Deductive vs Inductive Reasoning\n",
    "Deductive and inductive reasoning are two different approaches to reaching conclusions on the basis of logic. Deductive reasoning is based on starting with a general premise and then reaching a conclusion as a logical consequence. For instance:\n",
    "\n",
    "1. All humans are mortal.\n",
    "2. George is a human.\n",
    "3. Therefore, George is mortal.\n",
    "\n",
    "Here we start with a very general premise (*all humans are mortal*) and arrive at a specific example (*George is mortal*). If the premise is true, then the conclusion *has* to be true. We do not need to test this, we can arrive at this conclusion using pure reason[^george-foot]. Because of this, as long as our premise is correct, we can happily go from the *general* to the *specific* without a logical misstep. \n",
    "\n",
    "This type of reasoning can also take different forms. For instance, the *modus tollens* is a type of deductive argument where a condition is false because its expected outcome is false. For instance:\n",
    "\n",
    "1. If it is raining, the ground will be wet.\n",
    "2. The ground is not wet.\n",
    "3. Therefore, it is not raining.\n",
    "\n",
    "There is no way around this. If a logic consequence of rain is that the ground is wet, then the ground being dry *must* indicate that it is *not* raining. The only way this could not be wrong is if our premise is wrong. This is what makes mathematics so powerful, because *every* result is a deductive consequence of its axioms[^axiom-foot]. Mathematics is the most powerful deductive force in the world. So long as the axioms are true, everything else *has* to be true.\n",
    "\n",
    "Inductive reasoning, on the other hand, goes from the *specific* to the *general*. It involves generalising from what we have observed so far, and assuming that all cases we will ever observe in the future will be the same. For instance:\n",
    "\n",
    "1. All life forms so far discovered are composed of cells.\n",
    "2. Therefore, all life forms are composed of cells.\n",
    "\n",
    "This is exactly the form of reasoning that typifies scientific investigation. Unfortunately, unlike deductive reasoning, this is *not logically valid*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47953256",
   "metadata": {},
   "source": [
    "## The Problem of Induction\n",
    "\n",
    "```{figure} images/hulme.png\n",
    "---\n",
    "scale: 25%\n",
    "align: left\n",
    "---\n",
    "```\n",
    "\n",
    "The *problem of induction* refers to the logical issues surrounding the use of inductive reasoning in science, and was first articuled in 1739 by the Scottish philosopher [David Hulme](https://en.wikipedia.org/wiki/David_Hume) (who you can see on the left). The problem refers to the fact that there is no non-circular way of justifying why the specific cases of a phenomena observed thus far should give rise to the same phenomena in the future. The best we can often do is to appeal to the *uniformity of nature* and suggest that things must continue the way they have, because things always have. However, we know first hand that this is not a great argument, because things do not always have to proceed the way they have in the past. A pithy quote from [Bertrand Russell](https://en.wikipedia.org/wiki/Bertrand_Russell) makes this point clear:\n",
    "\n",
    "```{epigraph}\n",
    "Domestic animals expect food when they see the person who usually feeds them. We know that all these rather crude expectations of uniformity are liable to be misleading. The man who has fed the chicken every day throughout its life at last wrings its neck instead, showing that more refined views as to the uniformity of nature would have been useful to the chicken.\n",
    "\n",
    "-- Bertrand Russell, *The Problems of Philosophy* (1912)\n",
    "```\n",
    "\n",
    "As an example, why do you believe the sun will rise tomorrow morning? The answer is probably because it has always risen in the past. However, this is a circular argument because it relies on induction to justify induction. To make this clearer, the argument is\n",
    "\n",
    "1. The sun has risen every day in the past\n",
    "2. Therefore, the sun will rise tomorrow\n",
    "\n",
    "```{figure} images/circular-reasoning.jpg\n",
    "---\n",
    "scale: 40%\n",
    "align: right\n",
    "---\n",
    "```\n",
    "\n",
    "But to get from 1 to 2, you have to make the assumption that the future will always represent the past. You have justified the assumption that the future resembles the past by appealing to the fact that it has resembled the past in the past. The conclusion therefore cannot be reached with pure logic because it relies on an extra assumption. Or, to put it another way:\n",
    "\n",
    "\"predicting the future from the past works because predicting the future from the past works...\" \n",
    "\n",
    "We have justified our logic using the logic we are trying to justify. As such, Hulme's insight is that you can *never* deduce future regularities from past experience because this relies on circular reasoning[^probfoot]. So in what way are we ever able to logically justify reaching general conclusions from specific instances? This is not just an issue for statistics. Hume's insight was so devastating because it puts the whole enterprise of science into question. Far from being the most rational system we have for reaching conclusions about the world, it seems that science is, in fact, fundamentally *irrational*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6193016",
   "metadata": {},
   "source": [
    "## Statistical Inferences as Induction\n",
    "On the face of it, statistical inference is precisely an exercise in induction. As such, taking a hard-nosed perspective, statistical inference can *never* be logically justified. Fundamentally, statistical inference is based on assuming that predictions about the future will resemble the past and thus cannot be justified using pure logic. Although this may seem highly problematic, induction within statistics (as well as more broadly in science) can be coherently structured, pragmatically justified and rationally defensible, even if it cannot make peace with a pure framework of logic. In other words, statistical inference is *useful*, even if it is on shaky logical ground.\n",
    "\n",
    "....\n",
    "\n",
    "Although we would ideally want scientific reasoning to be deductive and thus justifiable purely on logical grounds, the process of scientific discovery usually takes the form\n",
    "\n",
    "1. If theory $T$ is true, then data $D$ is likely.\n",
    "2. We observe $D$.\n",
    "3. Therefore, $T$ is probably true.\n",
    "\n",
    "This is not deductive. Although the premises may well be correct, it does not follow that theory $T$ is true as there may be many other theories that could explain the observation of $D$. If we instead state that theory $T$ is *probably* true, then we have moved from pure reason into the world of probability. By saying that $T$ is *probably* true, we are accepting that it may be incorrect and thus the conclusion is not a certainty based on the premises.\n",
    "\n",
    "....\n",
    "\n",
    "The important point of all of this is that *inference is where the controversy lies*. There is nothing controversial about building a statistical model and then finding parameter estimates that make the data as probable as possible. What is controversial is trying to say something about the population as a whole based on that model. Indeed, arguments within statistics about Frequentist vs Bayesian approaches are often centred on how this different paradigms treat inductive inference. Furthermore, this is not just an issue with statistics, but with science as a whole. We assume that if our experiments have worked in the past, then they will continue to work in the future. But, as Hulme articulated, there is no pure logical justification for this. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372c3390",
   "metadata": {},
   "source": [
    "## Modern Science and Induction\n",
    "As we have now seen, it has been over 250 years since Hulme articulated the problem of induction, and yet science continues. So how has this problem been solved? In short, it has not. In fact, there is *no* solution to the problem of induction that has been successfully articulated. If we ironically apply the logic of induction, this suggests that no solution will ever be found. So how can science continue if its most basic principles are logically invalid? In this final section, we will have a look at some choice \"solutions\" to induction. Although we have already prefaced this section by saying that *no* solution to induction exists, that has not stopped philosophers of science from trying. The two major solutions that are of direct relevance here are Karl Popper's principle of *falsification* and the Bayesian perspective on induction. This is mainly because both of these are *practical* considerations of the problem, rather than metaphysical ones (such as [Kant's Transcendentalism](https://plato.stanford.edu/entries/kant-hume-causality/)). Neither of these approaches successfully solves induction, as one attempts to side-step induction whilst the other embraces a formal system for induction. However, these are both highly influential ideas in philosophy of science. Nevertheless, it is arguable that modern science uses *neither* of these suggestions. Instead, modern science generally falls-back on the philosophical principle of *pragmatism* to justify induction, as we will discuss further below.\n",
    "\n",
    "```{epigraph}\n",
    "It seems, then — and this is no longer controversial — that there is no solution to the problem of induction that could demonstrate with logical certainty the truth of general scientific theories.\n",
    "\n",
    "-- Howsen & Urbach, *Scientific Reasoning: The Bayesian Approach* (2006)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46ad047",
   "metadata": {},
   "source": [
    "### Popper's Falsificationism\n",
    "\n",
    "\n",
    "```{figure} images/popper.jpg\n",
    "---\n",
    "scale: 40%\n",
    "align: left\n",
    "---\n",
    "```\n",
    "\n",
    "In his 1959 book [The Logic of Scientific Discovery](https://www.librarysearch.manchester.ac.uk/permalink/44MAN_INST/1r887gn/alma9953976500001631), the German philosopher Karl Popper set out his solution to Hulme's problem of induction. Although Popper agreed that no amount of confirmatory evidence could ever *prove* a theory correct, he noted that a single piece of *disconfirmatory* evidence could render a theory *false*. As such, Popper reimagined the purpose of science not as an exercise in induction, but rather an exercise in *falsification*. If, over time, a theory resisted more and more precise attempts at falsification then Popper considered the theory to be *corroborated*, though never outright proven. As such, the theories that survive over time are the ones that have so far resisted falsification. Our aim, therefore, is to create theories that are falsifiable, and then attempt to falsify them. If they are falsified, we throw them away, if they resist falsification then we can say that they have thisfar been corroborated. \n",
    "\n",
    "Although Popper's idea of falsification can seem appealing at first, it is not without problems. Perhaps the biggest issue is that Popper's idea of how science *ought* to behave was not always compatible with how science *does* behave. For instance, it is rare that disconformatory evidence ever leads to a theory being outright abandoned. This is because there could be many reasons why a result has failed. Yes, the theory could be wrong, or it could be an issue with the data, or the precision of the measurement instrument, or human error, or a misunderstanding of certain assumptions. So without solid falsification, we just end up with a corpus of ambiguous findings. Scientists also do not just abandon theories at the first sign of trouble. The early experiments into Einstein's theory of relativity appeared inconsistent, but the theory was not suddenly abandoned. This is because the degree of deviation from the theory is not easy to quantify. Popper's view was that a single piece of evidence could shatter a theory, but in reality there is much ambiguity about what would actually count as disconformatory evidence. Furthermore, many competing theories can survive falsification, so how do we choose between them? In amassing corroborative evidence for one theory, we also corroborate other theories as well. So how do we use the logic of falsificationism to determine which theory to give preference to?\n",
    "\n",
    "Perhaps a final nail in the coffin of falsificationism is that it sneaks induction in through the backdoor. If we are using theories that have not yet been falsified, then we are implicitly endorsing the idea that the theory will continue to not be falsified. Otherwise, why would we be using it? If we are happy to use a current theory to make general predictions about the world because it has been thusfar corroborated, then we are engagaing in inductive logic. Our assumption is that a theory gets stronger the more attempts at falsification it survives. But this is assuming that past events will continue into the future. In other words, the continued use of unfalsified theories about the world is arguably an inductive act, even if Popper would refuse to admit it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c9be04",
   "metadata": {},
   "source": [
    "### Bayesian Scientific Reasoning\n",
    "An alternative to Popperian falsificationism is not to try and side-step induction. Instead, we should embrace induction as a necessary fact of science and try to develop a framework around it. This is the domain of Bayesian Scientific Reasoning, most clear elluciated by the philosophers Colin Howsen and Peter Urbach in their 2006 book [Scientific Reasoning: The Bayesian Approach](https://www.librarysearch.manchester.ac.uk/permalink/44MAN_INST/bofker/alma992975897924201631).  \n",
    "\n",
    "...The difference with Bayesian probability is that it represents *degree of belief* or a quantification of *uncertainty* given the current state of knowledge. Frequentist probability relies entirely on induction because it is defined as the long-run frequency of events. The future resembling the past is part of the *definition* of frequentist probability. ... Bayesian probability formalises the process of updating of our beliefs based on new data. This is then a *framework* for inductive inference. Our outcome is a probability derived from combining our current beliefs with new data and seeing how those beliefs change. This outcome is not a frequency, but a metric of our current uncertainty. Based on everything we know, this is how we believe things will be in the future. This does not solve induction, instead it *embraces* induction and the uncertainty around it. Furthermore, this matches intuitively with how we, as human beings, rationalise about the world. We have existing beliefs, we collect data and we update those beliefs. Bayesian Scientific Reasoning therefore reframes induction into an exercise in developing probabilistic beliefs about the world. We have a certain degree of certainty about the future, but also accept that we may be wrong. We know this cannot be deduced logically, but by combining our existing knowledge with data, we can make a prediction that we have a certain degree of personal certainty in.\n",
    "\n",
    "Importantly, this is *not* a solution to induction. This is induction *reframed*. So we have to accept induction and make peace with the fact that it is not logically justifiable. This may not feel particularly satisfying, but given that induction appears insolvable, there is arguably little else we can do. Beyond this uncomfortable conclusion, there are also concerns about how subjectivity enters Bayesian calculations of probability. All Bayesian probabilities necessitate the inclusion of *priors*, which are probabilistic statements about the phenomena under study *before* any data has been observed. In other words, these are your *personal beliefs* about the values of parameters and hypotheses. The degree to which you find this idea distasteful depends very much on your own personal view on subjectivity in science, though it is arguable that this is a natural and excepted part of the scientific endevour. As we will see by the end of this lesson, an obsessive drive towards objectivity can actually be counter-productive. Nevertheless, subjectivity of any form can appear wholly unscientific and there is no getting around the need for priors when calculating Bayesian probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70db8c08",
   "metadata": {},
   "source": [
    "### Modern Science and Pragmatism\n",
    "Pragmatism is therefore very much an *attitude* to the problem, rather than a formal solution.\n",
    "\n",
    "```{epigraph}\n",
    "If there is an order of nature which makes future events resemble past ones, the inductive method will find it. If there is no such order, the method will not work — but then, no method will work.\n",
    "\n",
    "-- Hans Reichenbach, *The Rise of Scientific Philosophy* (1951)\n",
    "```\n",
    "\n",
    "The problem of induction has not been solved. However, modern science has effectively *outmaneuvered* it on pragmatic grounds. ... However, it is important to understand the fact that statistical inference as an exercise in induction cannot be rationalised on pure logical ground. The act of performing inference is an act of pragmatic reasoning based on past success. However, there is no singular \"correct\" method for performing inference. We have one approach, called *null hypothesis significance testing*, that has gained much traction within the field of experimental psychology. However, this method is also controversial and other approaches do exist (such as Bayesian inference). In order to be a strong data analyst and experimental psychologist, this lack of logical grounding for inductive reasoning is important to understand, as well as how this influences the methods we use to try and make generalisations from our data, even if technically we have no logical justification for doing so.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06177402",
   "metadata": {},
   "source": [
    "[^probfoot]: You might think to skirt this issue by making it probabilistic. For instance, \"the sun has always risen in the past, therefore it is highly probable that it will rise tomorrow\". However, this has the same issue of circular reasoning because it requires the assumption that past frequencies of an event can justify a belief about the future. In doing so, our only argument is that this has worked in the past and we hit the same problem.\n",
    "\n",
    "[^george-foot]: Which is lucky for George.\n",
    "\n",
    "[^axiom-foot]: The axioms are the *rules* that govern mathematics. These are like the *premises* of all mathematics. So long as these are correct, everything that follows *must* be correct on purely logical grounds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f14eb4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
