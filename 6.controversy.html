
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>The Controversy of NHST &#8212; Linear Models II: Statistical Inference for Linear Models</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="_static/test.css?v=90b7ad94" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '6.controversy';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Summary" href="summary.html" />
    <link rel="prev" title="NHST III: Statistical Significance" href="5.null-hypothesis-testing-III.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="0.intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Linear Models II: Statistical Inference for Linear Models - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Linear Models II: Statistical Inference for Linear Models - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="0.intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="1.purpose-of-inference.html">The Purpose of Statistical Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="2.estimation-uncertainty.html">Uncertainty in Estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="3.null-hypothesis-testing-I.html">NHST I: The Null Hypothesis</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.null-hypothesis-testing-II.html">NHST II: Test Statistics</a></li>
<li class="toctree-l1"><a class="reference internal" href="5.null-hypothesis-testing-III.html">NHST III: Statistical Significance</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">The Controversy of NHST</a></li>
<li class="toctree-l1"><a class="reference internal" href="summary.html">Summary</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/PCHN63101-Advanced-Data-Skills/Inference-Linear-Model" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/PCHN63101-Advanced-Data-Skills/Inference-Linear-Model/issues/new?title=Issue%20on%20page%20%2F6.controversy.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/6.controversy.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>The Controversy of NHST</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problems-with-nhst">Problems with NHST</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#nhst-is-not-answering-the-right-question">1. NHST is Not Answering the Right Question</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-null-hypothesis-is-implausible">2. The Null Hypothesis is Implausible</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusions-from-nhst-are-logically-flawed">3. Conclusions From NHST are Logically Flawed</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#despite-appearances-nhst-is-not-objective">4. Despite Appearances, NHST is <em>Not</em> Objective</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#should-we-abandon-nhst">Should We Abandon NHST?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-asa-statement-on-p-values">The ASA Statement on <span class="math notranslate nohighlight">\(p\)</span>-values</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="the-controversy-of-nhst">
<h1>The Controversy of NHST<a class="headerlink" href="#the-controversy-of-nhst" title="Link to this heading">#</a></h1>
<p>In the previous part of this lesson, we explored the final part of the NHST machinery and came to a rather uncomfortable conclusion: the modern incarnation of NHST is actually an inconsistent mixture of two different philosophies of inference that were never designed to go together. Of course, this has not stopped people from calculating <span class="math notranslate nohighlight">\(p\)</span>-values, declaring significance and rejecting null hypotheses for many years. This can be justified on purely pragmatic grounds, especially as the practical conclusions from the two approach are often similar. As such, the complaints about these philosophical problems do not appear to matter too much in practice. However, this pragramtic argument suggests that, as long as you put these differences aside, NHST is a useful and meaningful procedure, hence why we are willing to overlook these issues. Unfortuantely, even when applied with a purely practical mindset, there are still many problems with this approach which cast doubt on how useful the procedure even is. In this final part of the lesson, we will explore a number of key issues that have been raised about NHST.</p>
<section id="problems-with-nhst">
<h2>Problems with NHST<a class="headerlink" href="#problems-with-nhst" title="Link to this heading">#</a></h2>
<p>We will start by examining some of the core issues with the practical application of NHST. Some of these issues are specifically with what NHST is doing, whereas others are issues with what researchers <em>think</em> NHST is doing. Although <em>misunderstanding</em> NHST may seem an unfair critique (after all, it is not the method’s fault if it is taught badly), these issues are so widespread that they <em>are</em> a problem with the application of NHST in practice. Indeed, such misunderstandings are sometimes illuminating because they indicate what researchers <em>want</em> NHST to tell them, even if it does not. If our main tool for inference is <em>unintuitive</em> and does not tell us what we want, is it really the best tool?</p>
<section id="nhst-is-not-answering-the-right-question">
<h3>1. NHST is Not Answering the Right Question<a class="headerlink" href="#nhst-is-not-answering-the-right-question" title="Link to this heading">#</a></h3>
<p>Perhaps the most fundamnetal issue with NHST, no matter whether you side with Fisher or Neyman-Pearson, is that it feels like we have spent a lot of time getting to a result that does not answer our question. Our conversation has gone:</p>
<ul class="simple">
<li><p>Researcher - “What value does this parameter have in the population?”</p></li>
<li><p>NHST - “Well, if it was 0 then these data wouldn’t be very likely!”</p></li>
<li><p>Researcher - “Ok…so there’s a low probably of it being 0?”</p></li>
<li><p>NHST - “No, sorry, you can’t say that”.</p></li>
</ul>
<p>The problem is that what we <em>really</em> want to know is <span class="math notranslate nohighlight">\(P(\beta_{1}|\mathcal{D})\)</span>. In other words, what are the most probable values of the population parameter, given our data? Alternatively, if we want to think in terms of null hypotheses, what we really want is <span class="math notranslate nohighlight">\(P(\mathcal{H}_{0}|\mathcal{D})\)</span>. In other words, what is the probability of the null hypothesis, given the data? In both cases, we are using probability in a Bayesian fashion and asking how much we <em>believe</em> different values of <span class="math notranslate nohighlight">\(\beta_{1}\)</span> or <em>believe</em> the possibility of the null, given our current knowledge and the information added by the data. In other words, we say that we are <em>uncertain</em> about these quantities and have used probability to quantify this uncertainty. This feels natural and intuitive, but goes directly against the Frequentist view. Within the frequentist framework, parameters are <em>constants</em> and hypotheses are either <em>true</em> or <em>false</em>. We cannot assign probability to them and so the statements above are effectively <em>meaningless</em>.</p>
<p>This is where the rigid framework of Frequentist statistics comes up against the more naturalistic Bayesian concept of probability. For Fisher and other Frequentists, calculating <span class="math notranslate nohighlight">\(P(\mathcal{D}|\beta_{1})\)</span> has meaning because the data are random and we can condition based on some proposed value for <span class="math notranslate nohighlight">\(\beta_{1}\)</span>. However, <span class="math notranslate nohighlight">\(P(\beta_{1}|\mathcal{D})\)</span> is <em>not</em> meaningful, because <span class="math notranslate nohighlight">\(\beta_{1}\)</span> is a constant and has no probabilistic behaviour. There is no long-run frequency interpretation where <span class="math notranslate nohighlight">\(P(\beta_{1})\)</span> makes sense. However, if you think of probability as <em>degree of belief</em> rather than <em>long-run frequency</em>, then <span class="math notranslate nohighlight">\(P(\beta_{1})\)</span> <em>does</em> make sense. This is why so many classical statistical results feel backwards or convoluted, because this definition of probability restricts the values that are sensible to calculate.</p>
<p>So, is NHST asking the right question? Arguably, the answer is <em>no</em>. What NHST is answering is the only question that it is allowed to answer. Data is random. Parameter <em>estimates</em> are random. The population parameters themseleves are constants. So we cannot talk about their probability, only the probability of the data or the probability of the estimates, conditional on assuming the population parameters have a certain fixed value. We cannot answer the question we want to using this framework. So why use Frequentist methods at all? For Fisher, Bayesian approaches were too <em>subjective</em> and his aim was to create a framework for inference that was <em>objective</em>. In doing so, he actively avoided quantities that require Bayesian methods, including <span class="math notranslate nohighlight">\(P(\beta_{1}|\mathcal{D})\)</span> or <span class="math notranslate nohighlight">\(P(\mathcal{H}_{0}|\mathcal{D})\)</span>. So, Frequentist methods were developed to <em>avoid</em> the questions that we would actually like to answer. This was done in the name of <em>objectivity</em><a class="footnote-reference brackets" href="#fiducialfoot" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>, though we will discuss how successful this was further below. However, there is also a practical argument in favour of Frequentist methods. Bayesian approaches are often computationally demanding meaning that, in the past, computational limitations meant that many Bayesian methods were simply <em>impossible</em> to implement by hand. This is no longer true, but does explain why Frequentist methods were favoured more, as their results were more tractable and easily applicable. For both these reasons, NHST became <em>the</em> dominant paradigm used by scientists during the 20th Century.</p>
</section>
<section id="the-null-hypothesis-is-implausible">
<h3>2. The Null Hypothesis is Implausible<a class="headerlink" href="#the-null-hypothesis-is-implausible" title="Link to this heading">#</a></h3>
<p>Another problem is one that is somewhat context-specific, but is almost always a problem in fields such as Experimental Psychology: the use of 0 as a null hypothesis. This is referred to as the <em>nil-hypothesis</em> by <a class="reference external" href="https://www.sjsu.edu/faculty/gerstman/misc/Cohen1994.pdf">Cohen (1994)</a>. The problem is that, for any real-world phenomena we can think of, the possibility of the true population value being <em>exactly 0</em> is almost never going to be true. For instance, a population correlation coefficient of <em>exactly</em> 0, or a group different of <em>exactly</em> 0. In fact, the problem exists for any value we choose as our null, because it is incredibly unlikely that we will hit upon the <em>exact</em> value down to every decimal point. In a field such as Physics, where very precise predictions can be made of single values, such a situation is perhaps less of a concern. However, when dealing with <em>human beings</em>, we do not have the theoretical ability to make such specific predictions. As such, as Experimental Psychologists, the null hypothesis is <em>almost never going to be true</em>.</p>
<p>Beyond wondering what the point is of testing a hypothesis that we can almost guarantee is false, this causes distinct issues for the behaviour of the <span class="math notranslate nohighlight">\(p\)</span>-value. Remembering that a <span class="math notranslate nohighlight">\(p\)</span>-value tells us how <em>consistent</em> our data are with the proposed null value, when the null is <em>not true</em> all that a non-significant <span class="math notranslate nohighlight">\(p\)</span>-value tells us is that we did not have enough data to see that it is not true. Even if the difference between the true value and our null is very slight, in principle we just need enough data. We can easily demonstrate this using simulations in <code class="docutils literal notranslate"><span class="pre">R</span></code>. If the true correlation in the population was very small (say <span class="math notranslate nohighlight">\(r = 0.06\)</span>), how much data would be needed for the <span class="math notranslate nohighlight">\(p\)</span>-value to be significant a <span class="math notranslate nohighlight">\(p &lt; 0.05\)</span>?</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">MASS</span><span class="p">)</span><span class="w">  </span><span class="c1"># for mvrnorm</span>

<span class="nf">set.seed</span><span class="p">(</span><span class="m">123</span><span class="p">)</span>

<span class="c1"># Parameters</span>
<span class="n">rho</span><span class="w">   </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0.06</span>
<span class="n">max_n</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">4000</span>
<span class="n">step</span><span class="w">  </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">50</span>
<span class="n">reps</span><span class="w">  </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">500</span>

<span class="c1"># Covariance matrix for bivariate normal</span>
<span class="n">Sigma</span><span class="w">        </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">matrix</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="n">rho</span><span class="p">,</span><span class="n">rho</span><span class="p">,</span><span class="m">1</span><span class="p">),</span><span class="m">2</span><span class="p">,</span><span class="m">2</span><span class="p">)</span>
<span class="n">sample_sizes</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">seq</span><span class="p">(</span><span class="n">step</span><span class="p">,</span><span class="w"> </span><span class="n">max_n</span><span class="p">,</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">step</span><span class="p">)</span>

<span class="c1"># Store mean p-values</span>
<span class="n">mean_pvals</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">numeric</span><span class="p">(</span><span class="nf">length</span><span class="p">(</span><span class="n">sample_sizes</span><span class="p">))</span>

<span class="nf">for </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="nf">seq_along</span><span class="p">(</span><span class="n">sample_sizes</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">n</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">sample_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<span class="w">  </span>
<span class="w">  </span><span class="n">pvals</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">numeric</span><span class="p">(</span><span class="n">reps</span><span class="p">)</span>
<span class="w">  </span>
<span class="w">  </span><span class="nf">for </span><span class="p">(</span><span class="n">r</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="n">reps</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">dat</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mvrnorm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">mu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">0</span><span class="p">),</span><span class="w"> </span><span class="n">Sigma</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Sigma</span><span class="p">)</span>
<span class="w">    </span><span class="n">test</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">cor.test</span><span class="p">(</span><span class="n">dat</span><span class="p">[,</span><span class="w"> </span><span class="m">1</span><span class="p">],</span><span class="w"> </span><span class="n">dat</span><span class="p">[,</span><span class="w"> </span><span class="m">2</span><span class="p">])</span>
<span class="w">    </span><span class="n">pvals</span><span class="p">[</span><span class="n">r</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">test</span><span class="o">$</span><span class="n">p.value</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span>
<span class="w">  </span><span class="n">mean_pvals</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">pvals</span><span class="p">)</span>
<span class="p">}</span>

<span class="nf">par</span><span class="p">(</span><span class="n">cex.lab</span><span class="o">=</span><span class="m">1.3</span><span class="p">,</span><span class="w"> </span><span class="n">cex.axis</span><span class="o">=</span><span class="m">1.1</span><span class="p">,</span><span class="w"> </span><span class="n">cex</span><span class="o">=</span><span class="m">1.4</span><span class="p">)</span><span class="w"> </span><span class="c1"># plot scaling</span>

<span class="c1"># Plot</span>
<span class="nf">plot</span><span class="p">(</span><span class="n">sample_sizes</span><span class="p">,</span><span class="w"> </span><span class="n">mean_pvals</span><span class="p">,</span><span class="w"> </span>
<span class="w">    </span><span class="n">type</span><span class="o">=</span><span class="s">&quot;l&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="o">=</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s">&quot;blue&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">ylim</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">1e-4</span><span class="p">,</span><span class="m">0.6</span><span class="p">),</span>
<span class="w">     </span><span class="n">xlab</span><span class="o">=</span><span class="s">&quot;Sample Size (n)&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">ylab</span><span class="o">=</span><span class="s">&quot;Average p-value&quot;</span><span class="p">,</span>
<span class="w">     </span><span class="n">main</span><span class="o">=</span><span class="s">&quot;Mean p-value vs Sample Size for r = 0.06&quot;</span><span class="p">)</span>

<span class="nf">abline</span><span class="p">(</span><span class="n">h</span><span class="o">=</span><span class="m">0.05</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s">&quot;red&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lty</span><span class="o">=</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="o">=</span><span class="m">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="_images/8579ae3705c291fd4f22729a98b5ed70b29e4dbb35a11cc2a916aa8b6ef4bb62.png"><img alt="_images/8579ae3705c291fd4f22729a98b5ed70b29e4dbb35a11cc2a916aa8b6ef4bb62.png" src="_images/8579ae3705c291fd4f22729a98b5ed70b29e4dbb35a11cc2a916aa8b6ef4bb62.png" style="width: 720px; height: 420px;" /></a>
</div>
</div>
<p>You may be surprised to see that the <span class="math notranslate nohighlight">\(p\)</span>-value is a function of sample size. But, as we can see above, the <span class="math notranslate nohighlight">\(p\)</span>-value will get smaller the more data we have. Based on this graph, we would need around 2,000 subjects for this correlation to be significant. This might sounds like a lot, but considering how available big datasets are these days (such as the UK Biobank with <span class="math notranslate nohighlight">\(n = 500,000\)</span>) and the ease of collecting questionnaire data online, <span class="math notranslate nohighlight">\(n = 2,000\)</span> is not really that unreasonable. Although you could argue that the necessary sample size alone should indicate a problem, this implies that there is some limit for <span class="math notranslate nohighlight">\(n\)</span>, above which we can no longer trust <span class="math notranslate nohighlight">\(p\)</span>-values. So what is this limit? The very fact that there is an implied limit suggests that there is something funamentally problematic with using <span class="math notranslate nohighlight">\(p\)</span>-values as evidence.</p>
<p>It is important here to recognise that the <span class="math notranslate nohighlight">\(p\)</span>-value is <em>not wrong</em>. The null hypothesis is that <span class="math notranslate nohighlight">\(r = 0\)</span>, but we know that this incorrect because <span class="math notranslate nohighlight">\(r = 0.06\)</span>. So the test is doing excactly what it is supposed to. The issue is that <em>statistical significance</em> does not mean <em>practical significance</em>. If we know that the null hypothesis is always going to be false (i.e. a correlation is never really going to be <em>exactly</em> 0), then all a non-significant <span class="math notranslate nohighlight">\(p\)</span>-value tells us is that we do not have enough data. In this example, we do not have enough data until we reach <span class="math notranslate nohighlight">\(n \approx 2,000\)</span>. The problem is, if we already know that logically the null hypothesis is wrong, what is the point of testing it? To drive this home, consider what a correlation of <span class="math notranslate nohighlight">\(r = 0.06\)</span> actually looks like.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">set.seed</span><span class="p">(</span><span class="m">666</span><span class="p">)</span>
<span class="n">corr.data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">mvrnorm</span><span class="p">(</span><span class="m">1000</span><span class="p">,</span><span class="w"> </span><span class="n">mu</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">0</span><span class="p">),</span><span class="w"> </span><span class="n">Sigma</span><span class="o">=</span><span class="n">Sigma</span><span class="p">)</span>
<span class="nf">par</span><span class="p">(</span><span class="n">cex.lab</span><span class="o">=</span><span class="m">1.3</span><span class="p">,</span><span class="w"> </span><span class="n">cex.axis</span><span class="o">=</span><span class="m">1.1</span><span class="p">,</span><span class="w"> </span><span class="n">cex</span><span class="o">=</span><span class="m">1.4</span><span class="p">)</span><span class="w"> </span><span class="c1"># plot scaling</span>
<span class="nf">plot</span><span class="p">(</span><span class="n">corr.data</span><span class="p">[,</span><span class="m">1</span><span class="p">],</span><span class="w"> </span><span class="n">corr.data</span><span class="p">[,</span><span class="m">2</span><span class="p">],</span><span class="w"> </span><span class="n">xlab</span><span class="o">=</span><span class="s">&quot;x1&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">ylab</span><span class="o">=</span><span class="s">&quot;x2&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="_images/9496dc25e22530e2fa9501c73f348a36fb3ae2876991543111a4a6cead36f037.png"><img alt="_images/9496dc25e22530e2fa9501c73f348a36fb3ae2876991543111a4a6cead36f037.png" src="_images/9496dc25e22530e2fa9501c73f348a36fb3ae2876991543111a4a6cead36f037.png" style="width: 720px; height: 420px;" /></a>
</div>
</div>
<p>Now imagine that this was presented to you as evidence of some effect, because <span class="math notranslate nohighlight">\(p &lt; 0.05\)</span>. Would you be convinced? If not, then you are agreeing that the <span class="math notranslate nohighlight">\(p\)</span>-value is not very useful here. All it tells us is that we had enough data to see that the correlation is not exactly 0. Of course, if you saw <span class="math notranslate nohighlight">\(r = 0.06\)</span> reported, you would immediately see that this is a vanishingly small correlation. But clearly you are not using the <span class="math notranslate nohighlight">\(p\)</span>-value here. Instead, you are admitting that the only useful measure is the <em>effect size</em>.</p>
</section>
<section id="conclusions-from-nhst-are-logically-flawed">
<h3>3. Conclusions From NHST are Logically Flawed<a class="headerlink" href="#conclusions-from-nhst-are-logically-flawed" title="Link to this heading">#</a></h3>
<p>Another problem with NHST is that the logic almost universally applied when reaching a conclusion from a <span class="math notranslate nohighlight">\(p\)</span>-value is flawed. To see this, let us first examine a valid application of <a class="reference external" href="https://en.wikipedia.org/wiki/Syllogism">syllogistic reasoning</a>. Consider the following adapted example from <a class="reference external" href="https://www.sjsu.edu/faculty/gerstman/misc/Cohen1994.pdf">Cohen (1994)</a>:</p>
<ol class="arabic simple">
<li><p>If a person is a Martian then they are not a Member of Parliment.</p></li>
<li><p>This person is a Member of Parliment.</p></li>
<li><p>Therefore, this person is not a Martian.</p></li>
</ol>
<p>Putting aside any personal paranoia about aliens invading our political system, this is a perfectly valid application of a <a class="reference external" href="https://en.wikipedia.org/wiki/Modus_tollens"><em>modus tollens</em></a> argument. The conclusion logically and irrefutably follows from the premises. However, we can reach an <em>invalid</em> conclusion if any of the premises are faulty.</p>
<ol class="arabic simple">
<li><p>If a person is British then they are not a Member of Parliment.</p></li>
<li><p>This person is a Member of Parliment.</p></li>
<li><p>Therefore, this person is not British.</p></li>
</ol>
<p>This is a perfectly valid argument, but the conclusion is not sensible because the first premise is wrong. <em>Some</em> British people are Members of Parliment. We can make the premise more correct by making it probabilistic.</p>
<ol class="arabic simple">
<li><p>If a person is British then it is unlikely that they are a Member of Parliment.</p></li>
<li><p>This person is a Member of Parliment.</p></li>
<li><p>Therefore, this person is unlikely to be British.</p></li>
</ol>
<p>Unfortunately, the application of logic has now failed and has led to a conclusion that is not sensible. The reason is that applying probability in this way is fraught with issues. Probability quantifies <em>belief</em> or <em>uncertainty</em>, rather than absolute truth. In fact, probability does not preserve truth in the same way as formal logic. This is precisely because there are <em>always exceptions</em>. As such, we can easily reach false conclusions, as shown above.</p>
<p>The error in assuming that someone is not British because they are a Member of Parliment should hopefully be clear. What is perhaps less immediately obvious is that the same error is made when we do the following:</p>
<ol class="arabic simple">
<li><p>If <span class="math notranslate nohighlight">\(H_{0}\)</span> is true, then it is unlikely we would have generated this result (i.e. the <span class="math notranslate nohighlight">\(p\)</span>-value will be small).</p></li>
<li><p>This result has been generated (i.e. we have calculated a small <span class="math notranslate nohighlight">\(p\)</span>-value).</p></li>
<li><p>Therefore, <span class="math notranslate nohighlight">\(H_{0}\)</span> is unlikely to be true.</p></li>
</ol>
<p>This is exactly the same logical form as above and yet it <em>sounds</em> like a plausible line of reasoning. Nevertheless, in the same vein as the example above, it is logically invalid. And yet, this is the conclusion that is implicitly reached by every significant finding in the experimental psychology literature. This is what <a class="reference external" href="https://www.sjsu.edu/faculty/gerstman/misc/Cohen1994.pdf">Cohen (1994)</a> refers to as “the illusion of obtaining improbability”. In fact, jumping from 2 to 3 above requires an <em>inductive leap</em> because it does not follow logically using deduction. So this is the inductive reasoning that lies at the heart of using NHST. We are rejecting the possibility that we observed something rare and are instead assuming that <span class="math notranslate nohighlight">\(H_{0}\)</span> is false. This is a <em>leap of faith</em> that cannot be deduced logically. So although the mathematics of calculating <span class="math notranslate nohighlight">\(p\)</span>-values are purely deductive, drawing conclusions about <span class="math notranslate nohighlight">\(H_{0}\)</span> based on <span class="math notranslate nohighlight">\(p\)</span>-value is inductive. In other words, this form of inference:</p>
<ul class="simple">
<li><p>Is not logically valid,</p></li>
<li><p>Is not guaranteed to be true, and</p></li>
<li><p>Relies on assumptions about the world that go beyond the data and the mathematics.</p></li>
</ul>
<p>Another way of thinking about this is that a probabilitsic conclusion has been reached about <span class="math notranslate nohighlight">\(H_{0}\)</span>, yet we know that a <span class="math notranslate nohighlight">\(p\)</span>-value is <em>not</em> a probability statement about <span class="math notranslate nohighlight">\(H_{0}\)</span>. Instead, a <span class="math notranslate nohighlight">\(p\)</span>-value is a probability statement about the <em>data</em>. In other words, <span class="math notranslate nohighlight">\(p = P(\mathcal{D}|H_{0}) \neq P(H_{0}|\mathcal{D})\)</span>. As such, no statement can be made about how likely or unlikely <span class="math notranslate nohighlight">\(H_{0}\)</span> is, given the current data. Although <span class="math notranslate nohighlight">\(P(\mathcal{D}|H_{0})\)</span> and <span class="math notranslate nohighlight">\(P(H_{0}|\mathcal{D})\)</span> sound very similar, they are not the same quantity (as discussed further in the drop-down box below). From a pure Frequentist perspective, if we have a significant <span class="math notranslate nohighlight">\(p\)</span>-value we can conclude that our data are unlikely if the null hypothesis were true. We cannot make any statement about the null hypothesis itself, no matter how much we want to.</p>
<blockquote class="epigraph">
<div><p>What’s wrong with NHST? Well, among many other things, it does not tell us what we want to know, and we
so much want to know what we want to know that, out of desperation, we nevertheless believe that it does!</p>
<p class="attribution">—Jacob Cohen</p>
</div></blockquote>
<div class="tip dropdown admonition">
<p class="admonition-title">Why <span class="math notranslate nohighlight">\(P(\mathcal{D}|H_{0}) \neq P(H_{0}|\mathcal{D})\)</span></p>
<p>It can be helpful in trying to understand why the two statements <span class="math notranslate nohighlight">\(P(\mathcal{D}|H_{0})\)</span> and <span class="math notranslate nohighlight">\(P(H_{0}|\mathcal{D})\)</span> are <em>not</em> the same quantity by studying an example. This is taken from <a class="reference external" href="https://www.sjsu.edu/faculty/gerstman/misc/Cohen1994.pdf">Cohen (1994)</a> and concerns the results of a new test for Schizophrenia. Based on testing 1,000 random individual from the whole population, we have:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Result</p></th>
<th class="head"><p>Normal</p></th>
<th class="head"><p>Schiz</p></th>
<th class="head text-right"><p>Total</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>Negative test (Normal)</p></td>
<td><p>949</p></td>
<td><p>1</p></td>
<td class="text-right"><p>950</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Positive test (Schiz)</p></td>
<td><p>30</p></td>
<td><p>20</p></td>
<td class="text-right"><p>50</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Total</p></td>
<td><p>979</p></td>
<td><p>21</p></td>
<td class="text-right"><p>1000</p></td>
</tr>
</tbody>
</table>
</div>
<p>To put this into the framework of NHST, let us then assume:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(H_{0}\)</span> = An individual is “normal”</p></li>
<li><p><span class="math notranslate nohighlight">\(H_{1}\)</span> = An individual has Schizophrenia</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathcal{D}\)</span> = The test result is positive for Schizophrenia</p></li>
</ul>
<p>From here, let us see what the <span class="math notranslate nohighlight">\(p\)</span>-value tells us. Remembering that <span class="math notranslate nohighlight">\(p = P(\mathcal{D}|H_{0})\)</span>, we are therefore conditioning on <span class="math notranslate nohighlight">\(H_{0}\)</span> being true. For the table above, that means we are only looking at the <em>first column</em>. Based on this column alone, what is the probability that the result is positive? In this instance, we would calculate <span class="math notranslate nohighlight">\(30\)</span> positive results out of a total of <span class="math notranslate nohighlight">\(979\)</span>, which gives a <span class="math notranslate nohighlight">\(p\)</span>-value of <span class="math notranslate nohighlight">\(30/979 = 0.031\)</span>. So we would say that this is a <em>significant</em> result. In other words, if it is true that the individual is “normal”, the chance of getting a positive test result is small. Given our usual convention, we would therefore <em>reject the null-hypothesis</em> that the individual is “normal”.</p>
<p>Now let us see what <span class="math notranslate nohighlight">\(P(H_{0}|\mathcal{D})\)</span> tells us. This time, we are conditioning on the data we have obtained. Because these data indicate a <em>positive</em> test result, this means only looking at the <em>second row</em> of the table. Here, we want to know, out of all individuals who recieved a positive test result, how likely is it that they are “normal”? In this instance, we would calculate <span class="math notranslate nohighlight">\(30\)</span> “normal” individuals out of a total of <span class="math notranslate nohighlight">\(50\)</span> individuals who recieved a positive test, which gives a probability of <span class="math notranslate nohighlight">\(30/50 = 0.60\)</span>. So far from the null hypothesis being unlikely, it is actually fairly probable that the null hypothesis is <em>true</em>, given the data we have.</p>
<p>In this example, the extreme difference comes from the low base-rate of Schizophrenia. If we pluck a random individual off the street, it is fairly unlikely that they have Schizophrenia. Even if they test positive, it still remains unlikely that we found someone with Schizophrenia by chance. However, if we know ahead of time that we have only selected individuals <em>without</em> Schizophrenia, the chance of the test coming back positive is very low. This is the difference between conditioning on the data versus conditioning on the null. This illustrates why the two probability statements are not interchangeable, and also illustrates why you cannot say anything about the probability of the null from a <span class="math notranslate nohighlight">\(p\)</span>-value because the calculation of the <span class="math notranslate nohighlight">\(p\)</span>-value <em>presupposes the null is true</em>.</p>
</div>
</section>
<section id="despite-appearances-nhst-is-not-objective">
<h3>4. Despite Appearances, NHST is <em>Not</em> Objective<a class="headerlink" href="#despite-appearances-nhst-is-not-objective" title="Link to this heading">#</a></h3>
<p>It has been stated already that Fisher’s main motivating factor for developing Frequentist methods was that he believed that Bayesian methods were too subjective and that there was no room for <em>personal belief</em> within science. His aim was to create an alternative that was <em>objective</em>, and NHST was the result. Unfortuantely, despite Fisher’s efforts, many parts of NHST remain highly subjective:</p>
<ul class="simple">
<li><p>The threshold for significance itself is <em>arbitrary</em>. Although Fisher did not condone hard thresholds, his heuristic of <span class="math notranslate nohighlight">\(p = 0.05\)</span> remains a subjective marker for “significance”. There is no argument to be made that can objectively justify why <span class="math notranslate nohighlight">\(1/20\)</span> is a meaningful yardstick. Obviously, this gets worse when moving to the Neyman-Pearson approach and making hard decisions based on an arbitrary <span class="math notranslate nohighlight">\(\alpha\)</span>-level.</p></li>
<li><p>The results of NHST are highly dependent on the decisions of the data analyst. Choices about the model form, variables, null value, test-statistic and direction of the test are all based on subjective decisions made by the researcher. These <em>researcher degrees of freedom</em> are unavoidable, but can have a big impact on the resultant <span class="math notranslate nohighlight">\(p\)</span>-value.</p></li>
</ul>
<p>So, far from being the <em>objective</em> method that Fisher desired, NHST simply displaces subjectivity into the modelling decisions of the data analyst and arbitrary heuristics and thresholds for interpretation. This leads to a method that is unable to be purely objective, but in trying to be objective ends up answering questions we are not interested in. The fact of the matter is that subjectivity is an unescapable part of science, whether we like it or not. Indeed, this obsessive strive for objectivity backs NHST into a corner where it is unable to say much that is useful. Rather than fighting it, we need to embrace the fact that some degree of personal belief will <em>always</em> be a part of science. As the philosopher’s <a class="reference external" href="https://www.librarysearch.manchester.ac.uk/permalink/44MAN_INST/bofker/alma992975897924201631">Howson &amp; Urbach (2006)</a> put it:</p>
<blockquote class="epigraph">
<div><p>There is a subjective element…which offends some, but which, we submit, is wholly realistic. Perfectly sane scientists with access to the same information often do evaluate theories differently…You might take the view that…responsible scientists ought not to let personal, subjective factors influence their beliefs. But then you would have to face the fact that this view is itself a prejudice, because despite an immense intellectual effort, no one has produced a coherent defence of it, let alone a proof.</p>
<p class="attribution">—Howson &amp; Urback, <em>Scientific Reasoning: The Bayesian Approach</em> (2006, pg. 262-63)</p>
</div></blockquote>
</section>
</section>
<section id="should-we-abandon-nhst">
<h2>Should We Abandon NHST?<a class="headerlink" href="#should-we-abandon-nhst" title="Link to this heading">#</a></h2>
<section id="the-asa-statement-on-p-values">
<h3>The ASA Statement on <span class="math notranslate nohighlight">\(p\)</span>-values<a class="headerlink" href="#the-asa-statement-on-p-values" title="Link to this heading">#</a></h3>
<p>This statement is based on 6 key principles:</p>
<ol class="arabic simple">
<li><p>P-values can indicate how incompatible the data are with a specified statistical model.</p></li>
<li><p>P-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone.</p></li>
<li><p>Scientific conclusions and business or policy decisions should not be based only on whether a p-value passes a specific threshold.</p></li>
<li><p>Proper inference requires full reporting and transparency</p></li>
<li><p>A p-value, or statistical significance, does not measure the size of an effect or the importance of a result.</p></li>
<li><p>By itself, a p-value does not provide a good measure of evidence regarding a model or hypothesis.</p></li>
</ol>
<p>Taken together, these principles highlight how basing much of our scientific knowledge on <span class="math notranslate nohighlight">\(p\)</span>-values alone is deeply flawed and misleading. Yet, this is precisely what the field of experimental psychology has done for years.</p>
<p>So, based on all this, should we be using <span class="math notranslate nohighlight">\(p\)</span>-values and, more generally, the framework of NHST at all?</p>
<hr class="footnotes docutils" />
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="fiducialfoot" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>Fisher <em>knew</em> that frequentist probabilities about data conditional on some population value were unsatisfying. He also knew that what researchers wanted was a quantity more like <span class="math notranslate nohighlight">\(P(\beta_{1}|\mathcal{D})\)</span>. In order to do this <em>without</em> Bayesian methods, he tried to invent a new type of probability called <em>fiducial</em> probability to get probability statements about parameters. This was generally considered a failure, but does highlight that even the father of Frequentist methods knew that they were answering the wrong question.</p>
</aside>
</aside>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "r"
        },
        kernelOptions: {
            name: "ir",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'ir'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="5.null-hypothesis-testing-III.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">NHST III: Statistical Significance</p>
      </div>
    </a>
    <a class="right-next"
       href="summary.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Summary</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problems-with-nhst">Problems with NHST</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#nhst-is-not-answering-the-right-question">1. NHST is Not Answering the Right Question</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-null-hypothesis-is-implausible">2. The Null Hypothesis is Implausible</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusions-from-nhst-are-logically-flawed">3. Conclusions From NHST are Logically Flawed</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#despite-appearances-nhst-is-not-objective">4. Despite Appearances, NHST is <em>Not</em> Objective</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#should-we-abandon-nhst">Should We Abandon NHST?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-asa-statement-on-p-values">The ASA Statement on <span class="math notranslate nohighlight">\(p\)</span>-values</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Dr George Farmer & Dr Martyn McFarquhar
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2026.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>