{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a6b3fd6-1753-45e7-a920-fccf68cbdcac",
   "metadata": {},
   "source": [
    "# What Can We Do?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaa44ae",
   "metadata": {},
   "source": [
    "## Treat $p$-values as Only *One* Piece of Evidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3eef5c",
   "metadata": {},
   "source": [
    "## Focus on Effects and Effect Sizes \n",
    "\n",
    "An issue with effect sizes is that we need some means of interpreting them, which requires some guidelines for \"small\", \"medium\" and \"large\" effects. If one core issue with $p$-values is that they dichotomise evidence, then this new system just serves to *trichotomise* evidence instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517197b3",
   "metadata": {},
   "source": [
    "## Mayo's Severe Test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3b8ad3",
   "metadata": {},
   "source": [
    "## Use Bayesian Inference Instead\n",
    "\n",
    "Much of the complexity in classical statistics comes from\n",
    "\n",
    "- Imposing a pure frequency perspective on probability\n",
    "- Trying to enforce objectivity on statistical procedure, rather than embracing subjectivity\n",
    "\n",
    "On the face of it, these both sound like reasonable and noble pursuits, but in reality they can cause problems. ... From a Frequentist perspective, talking about the probability of the null hypothesis makes no sense. Hypotheses are not random variables, they are fixed quantities. The only random element is the data. There is no long-run frequency of a hypothesis that can be used to derive a probability. As such, the quantity $P(H_{0}|\\mathcal{D})$ is meaningless to a Frequentist[^freqprobfoot]. However, for a Bayesian, probability reflects *degrees of belief* or *plausibility* given our current state of knowledge. As such, the probability of the null makes perfect sense, as this reflects how plausible the null is, or how much we believe in the null, given our current data. Given that it is often our intuition to try and derive the probability of the null, it would seem that many people take a natural Bayesian view of probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bb952d",
   "metadata": {},
   "source": [
    "## The New Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494b838a",
   "metadata": {},
   "source": [
    "[^freqprobfoot]: To make this clear for the example we saw earlier, a Frequentist would say that calculating the probability that an individual is \"normal\" makes no sense, because they either are \"normal\" or have Schizophrenia. There is no long-run frequency where that individual is sometimes \"normal\" and is sometimes not. Their diagnostic status is a fixed constant. For a Bayesian, this *does* make sense because this probability reflects our *degree of belief* that the person is \"normal\", given our current data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffbb3db",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
